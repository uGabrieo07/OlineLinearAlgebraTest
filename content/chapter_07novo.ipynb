{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a0a7d5e-60af-4ebc-9bb8-b55227523a1e",
   "metadata": {},
   "source": [
    "# The Singular Value Decomposition\n",
    "\n",
    "Matrix decompositions are helpful in many ways. The\n",
    "$\\mathbf{P}\\mathbf{L}\\mathbf{U}$ and the spectral decompositions in\n",
    "chapters <a href=\"#chap:Ax=b\" data-reference-type=\"ref\"\n",
    "data-reference=\"chap:Ax=b\">[chap:Ax=b]</a>\n",
    "and <a href=\"#chap:eigenvalues_eigenvectors\" data-reference-type=\"ref\"\n",
    "data-reference=\"chap:eigenvalues_eigenvectors\">[chap:eigenvalues_eigenvectors]</a>\n",
    "are just two examples. In this chapter, we will present a broadly\n",
    "applicable and very general factorization of matrices as the product of\n",
    "an orthogonal matrix $\\mathbf{U}$, a diagonal matrix\n",
    "$\\boldsymbol{\\Sigma}$, and another orthogonal matrix\n",
    "$\\mathbf{V}^{\\rm T}$. This is called the singular value decomposition\n",
    "(SVD), and its roots date back to the nineteenth century, even before\n",
    "the widespread use of matrices. Although the definition of the SVD\n",
    "decomposition is straightforward, the proof of its existence is\n",
    "enlightening.\n",
    "\n",
    "## Definition and Existence of the SVD\n",
    "\n",
    "Let $\\mathbf{A}:\\mathbb{R}^n\\rightarrow\\mathbb{R}^m$ be a linear\n",
    "transformation induced by matrix $\\mathbf{A}$. We maintain that\n",
    "$\\mathbf{A}$ can be factored into\n",
    "$$\\mathbf{A}= \\mathbf{U}\\boldsymbol{\\Sigma}\\mathbf{V}^{\\rm T}\n",
    "  \\label{eq:svd}$$ where $\\mathbf{U}$ and $\\mathbf{V}$ are orthogonal\n",
    "matrices and $\\boldsymbol{\\Sigma}$ is an $m\\times n$ matrix with all\n",
    "entries equal to zero, except those in its diagonal, $\\sigma_{ii}$,\n",
    "which may be different from zero, but never negative. These are called\n",
    "the singular values of the linear transformation $\\mathbf{A}$. We will\n",
    "show below that $\\mathbf{U}$ and $\\mathbf{V}$ are orthogonal matrices\n",
    "whose columns are the normalized eigenvectors of\n",
    "$\\mathbf{A}\\mathbf{A}^{\\rm T}$ and $\\mathbf{A}^{\\rm T}\\mathbf{A}$,\n",
    "respectively. $\\boldsymbol{\\Sigma}$ is an $m\\times n$ matrix with the\n",
    "positive square roots of their eigenvalues on the diagonal, and zeros\n",
    "elsewhere.\n",
    "\n",
    "In order to go into the details and prove the existence of the\n",
    "decomposition, we will follow a strategy closely related to that offered\n",
    "by Beltrami [1]  \\[@Stew1993\\].\n",
    "\n",
    "Let $\\mathbf{x}\\in\\mathbb{R}^m$ and $\\mathbf{y}\\in\\mathbb{R}^n$ be\n",
    "arbitrary vectors. We can write a bilinear function\n",
    "$f(\\mathbf{x},\\mathbf{y}):\\mathbb{R}^m\\times\\mathbb{R}^n\\rightarrow\\mathbb{R}$\n",
    "as $$f(\\mathbf{x},\\mathbf{y})=\\mathbf{x}^{\\rm T}\\mathbf{A}\\mathbf{y}$$\n",
    "\n",
    "Now let $\\{\\mathbf{u}_i\\},\\ i=1,\\ 2,\\ \\ldots,\\ m$ and\n",
    "$\\{\\mathbf{v}_i\\},\\ i=1,\\ 2,\\ \\ldots,\\ n$ be orthonormal bases of\n",
    "$\\mathbb{R}^m$ and $\\mathbb{R}^n$, respectively. Vectors $\\mathbf{x}$\n",
    "and $\\mathbf{y}$ can be written as linear combinations of the vectors in\n",
    "the corresponding basis as $$\\mathbf{x}=\\mathbf{U}\\boldsymbol{\\xi}$$ and\n",
    "$$\\mathbf{y}=\\mathbf{V}\\boldsymbol{\\eta}$$ where matrices $\\mathbf{U}$\n",
    "and $\\mathbf{V}$ contain the basis’ vectors in their columns, as\n",
    "follows:\n",
    "$$\\mathbf{U}=\\left[\\mathbf{u}_1\\ \\ \\mathbf{u}_2\\ \\ \\cdots\\ \\ \\mathbf{u}_m\\right]$$\n",
    "and\n",
    "$$\\mathbf{V}=\\left[\\mathbf{v}_1\\ \\ \\mathbf{v}_2\\ \\ \\cdots\\ \\ \\mathbf{v}_n\\right]$$\n",
    "Therefore, the bilinear function becomes $$\\begin{split}\n",
    "  f(\\mathbf{x},\\mathbf{y})&=\\boldsymbol{\\xi}^{\\rm T}\\mathbf{U}^{\\rm T}\\mathbf{A}\\mathbf{V}\\boldsymbol{\\eta}\\\\\n",
    "              &=\\boldsymbol{\\xi}^{\\rm T}\\boldsymbol{\\Sigma}\\boldsymbol{\\eta}\n",
    "\\end{split}$$ where\n",
    "$$\\boldsymbol{\\Sigma}=\\mathbf{U}^{\\rm T}\\mathbf{A}\\mathbf{V}$$\n",
    "\n",
    "Given that $\\mathbf{U}$ and $\\mathbf{V}$ are orthogonal matrices, then\n",
    "$$\\mathbf{U}^{\\rm T}\\mathbf{A}=\n",
    "  \\boldsymbol{\\Sigma}\\mathbf{V}^{\\rm T}\\Rightarrow \\mathbf{U}^{\\rm T}\\mathbf{A}\\mathbf{A}^{\\rm T}\\mathbf{U}=\\boldsymbol{\\Sigma}\\boldsymbol{\\Sigma}^{\\rm T}$$\n",
    "and $$\\mathbf{A}\\mathbf{V}=\n",
    "  \\mathbf{U}\\boldsymbol{\\Sigma}\\Rightarrow \\mathbf{V}^{\\rm T}\\mathbf{A}^{\\rm T}\\mathbf{A}\\mathbf{V}=\\boldsymbol{\\Sigma}^{\\rm T}\\boldsymbol{\\Sigma}$$\n",
    "Furthermore, as $\\mathbf{A}\\mathbf{A}^{\\rm T}$ and\n",
    "$\\mathbf{A}^{\\rm T}\\mathbf{A}$ are both symmetric, we can choose\n",
    "$\\{\\mathbf{u}_i\\}$ and $\\{\\mathbf{v}_i\\}$ as their respective\n",
    "orthonormal eigenvectors. As a consequence of this choice, by the\n",
    "spectral decomposition seen in\n",
    "section <a href=\"#sec:sym_matrices\" data-reference-type=\"ref\"\n",
    "data-reference=\"sec:sym_matrices\">[sec:sym_matrices]</a>, matrices\n",
    "$\\boldsymbol{\\Sigma}\\boldsymbol{\\Sigma}^{\\rm T}=\\boldsymbol{\\Lambda}$\n",
    "and\n",
    "$\\boldsymbol{\\Sigma}^{\\rm T}\\boldsymbol{\\Sigma}=\\boldsymbol{\\Lambda}^\\prime$\n",
    "are both diagonal and carry the eigenvalues of\n",
    "$\\mathbf{A}\\mathbf{A}^{\\rm T}$ and $\\mathbf{A}^{\\rm T}\\mathbf{A}$,\n",
    "respectively. Therefore\n",
    "$$\\mathbf{A}\\mathbf{A}^{\\rm T}\\mathbf{u}_i=\\lambda_i\\mathbf{u}_i \n",
    "  \\Rightarrow \n",
    "  \\mathbf{A}^{\\rm T}\\mathbf{A}\\mathbf{A}^{\\rm T}\\mathbf{u}_i=\\lambda_i\\mathbf{A}^{\\rm T}\\mathbf{u}_i$$\n",
    "From the equation above, we realize that $\\mathbf{A}\\mathbf{A}^{\\rm T}$\n",
    "and $\\mathbf{A}^{\\rm T}\\mathbf{A}$ share the same eigenvalues\n",
    "$\\{\\lambda_i\\}$, $i=1,\\ \\ldots,\\ r\\le\\min(m,n)$, associated with\n",
    "eigenvectors which are related by the linear transformation\n",
    "$\\mathbf{A}^{\\rm T}$. Let us denote $\\bar{\\mathbf{v}}_i$, an\n",
    "unnormalized version of the eigenvector $\\mathbf{v}_i$ of\n",
    "$\\mathbf{A}^{\\rm T}\\mathbf{A}$, as $$\\label{eq:vi_bar}\n",
    "  \\bar{\\mathbf{v}}_i=\\mathbf{A}^{\\rm T}\\mathbf{u}_i$$\n",
    "\n",
    "On the other hand,\n",
    "$$\\boldsymbol{\\Sigma}=\\mathbf{U}^{\\rm T}\\mathbf{A}\\mathbf{V}\\Rightarrow \\mathbf{A}^{\\rm T}\\mathbf{U}= \\mathbf{V}\\boldsymbol{\\Sigma}^{\\rm T}$$\n",
    "or, equivalently, $$\\label{eq:vi}\n",
    "  \\mathbf{A}^{\\rm T}\\left[\\mathbf{u}_1\\ \\ \\mathbf{u}_2 \\ \\ \\cdots \\ \\ \\mathbf{u}_m\\right] =\n",
    "  \\left[\\mathbf{v}_1\\ \\ \\mathbf{v}_2\\ \\ \\cdots \\ \\ \\mathbf{v}_n\\right]\\boldsymbol{\\Sigma}^{\\rm T}\n",
    "  \\Rightarrow \n",
    "  \\mathbf{A}^{\\rm T}\\mathbf{u}_i = \\sum_{j=1}^{n}\\sigma_{ji}\\mathbf{v}_i\n",
    "  \\quad \n",
    "  i=1,\\ 2,\\ \\ldots,\\ m$$ From\n",
    "equations <a href=\"#eq:vi_bar\" data-reference-type=\"ref\"\n",
    "data-reference=\"eq:vi_bar\">[eq:vi_bar]</a>\n",
    "and <a href=\"#eq:vi\" data-reference-type=\"ref\"\n",
    "data-reference=\"eq:vi\">[eq:vi]</a>, we realize that $\\sigma_{ji}=0$ for\n",
    "all $i\\ne j$. Therefore $\\boldsymbol{\\Sigma}$ is “nonsquare diagonal”\n",
    "and can be constructed with the positive square roots of the nonzero\n",
    "eigenvalues of either $\\mathbf{A}\\mathbf{A}^{\\rm T}$, or\n",
    "$\\mathbf{A}^{\\rm T}\\mathbf{A}$.\n",
    "\n",
    "At this point, a note on the indexes feels necessary. In case $n<m$, the\n",
    "last $m-n$ eigenvalues of $\\mathbf{A}\\mathbf{A}^{\\rm T}$ are equal to\n",
    "$\\lambda_{n+1}=\\lambda_{n+2}=\\cdots=\\lambda_m=0$. Similarly, for $m<n$,\n",
    "the last $n-m$ eigenvalues of $\\mathbf{A}^{\\rm T}\\mathbf{A}$ are equal\n",
    "to $\\lambda_{m+1}=\\lambda_{m+2}=\\cdots=\\lambda_n=0$.\n",
    "\n",
    "## Calculating the SVD\n",
    "\n",
    "The results presented in\n",
    "section <a href=\"#sec:sym_matrices\" data-reference-type=\"ref\"\n",
    "data-reference=\"sec:sym_matrices\">[sec:sym_matrices]</a> ensure that\n",
    "there exist orthonormal eigenvectors of $\\mathbf{A}\\mathbf{A}^{\\rm T}$\n",
    "and $\\mathbf{A}^{\\rm T}\\mathbf{A}$ that form bases of $\\mathbb{R}^m$ and\n",
    "$\\mathbb{R}^n$, respectively, associated with real eigenvalues. The\n",
    "quadratic form of these symmetric matrices also guarantee that the\n",
    "eigenvalues are nonnegative:\n",
    "$\\boldsymbol{\\Lambda}=\\boldsymbol{\\Sigma}\\boldsymbol{\\Sigma}^{\\rm T}$\n",
    "and\n",
    "$\\boldsymbol{\\Lambda}^\\prime=\\boldsymbol{\\Sigma}^{\\rm T}\\boldsymbol{\\Sigma}$.\n",
    "\n",
    "A generic algorithm for obtaining matrices $\\mathbf{U}$,\n",
    "$\\boldsymbol{\\Sigma}$, and $\\mathbf{V}$ is as follows.\n",
    "\n",
    "$\\{\\mathbf{u}_i\\}\\gets$ orthonormal eigenvectors of\n",
    "$\\mathbf{A}\\mathbf{A}^{\\rm T},\\ \\ i=1,\\ 2,\\ \\ldots,\\ m$, associated with\n",
    "eigenvalues in nonincreasing order of magnitude, i.e.,\n",
    "$\\lambda_1\\ge\\lambda_2\\ge\\cdots\\ge\\lambda_m$\n",
    "$\\{\\sigma_{ii}\\}\\gets\\sqrt{\\lambda_i},\\ \\ i=1,\\ 2,\\ \\ldots,\\ \\min{(m,n)}$\n",
    "$\\{\\bar{\\mathbf{v}}_i\\}\\gets\\mathbf{A}^{\\rm T}\\mathbf{u}_i,\\ \\ i=1,\\ 2,\\ \\ldots,\\ \\min{(m,n)}$\n",
    "$\\{\\bar{\\mathbf{v}}_{m+1},\\ \\bar{\\mathbf{v}}_{m+2},\\ \\ldots,\\ \\bar{\\mathbf{v}}_n\\}\\gets$\n",
    "orthonormal vectors which are orthogonal to\n",
    "$\\{\\bar{\\mathbf{v}}_i\\},\\ \\ i=1,\\ 2,\\ \\ldots,\\ m$\n",
    "$\\{\\mathbf{v}_i\\}\\gets\\bar{\\mathbf{v}}_i/\\|\\bar{\\mathbf{v}}_i\\|,\\ \\ i=1,\\ 2,\\ \\ldots,\\ n$\n",
    "\n",
    "\n",
    "## Geometric considerations\n",
    "\n",
    "[1] E. Beltrami, *Sulle Funzioni Bilineari*, 1873 \\[@Belt1873\\]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeef0554",
   "metadata": {},
   "source": [
    "## Applications\n",
    "\n",
    "One of the main utilities of the SVD decomposition is to organize and comprehend the relevance of certain data. One of the fields in which this can be applied is image processing. If we observe a gray image as a matrix, we can apply SVD decomposition to the image, and observe in the ${\\Sigma}$ matrix the relevance of the pixels in each column to the composition of the image. \n",
    "This procedure can help us properly reduce images, since it is made certain that the least relevant information is eliminated.\n",
    "See this for yourself in the example below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68b33045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2dcd790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import img_as_ubyte, img_as_float\n",
    "gray = {\"cat\":rgb2gray(img_as_float(data.chelsea())),\n",
    "       \"astronaut\": rgb2gray(img_as_float(data.astronaut())),\n",
    "       \"photographer\": data.camera(),\n",
    "       \"coffee\": rgb2gray(img_as_float(data.coffee()))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9722ccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41c806b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decsvd(image, k):\n",
    "    U, S, V = svd(image, full_matrices=False)\n",
    "    product = np.dot(U[:,:k], np.dot(np.diag(S[:k]), V[:k,:]))\n",
    "    return product, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5d8e090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c679354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img_name, k):\n",
    "    image = gray[img_name]\n",
    "    original_shape = image.shape\n",
    "    reconst_img, s = decsvd(image,k)\n",
    "    fig, axes = plt.subplots(1,2,figsize=(8,5))\n",
    "    axes[0].plot(s)\n",
    "    compression_ratio = 100.0*(k*(original_shape[0] + original_shape[1])+k)/(original_shape[0]*original_shape[1])\n",
    "    axes[1].set_title(\"compression ratio={:.2f}\".format(compression_ratio)+\"%\")\n",
    "    axes[1].imshow(reconst_img, cmap='gray')\n",
    "    axes[1].axis('off')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec2cb3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q ipywidgets==8.0.7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e650727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "234c8953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1020576b00344183b37585758ba1f61d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='img_name', options=('cat', 'astronaut', 'photographer', 'coffee'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_img(img_name, k)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(show_img, img_name=list(gray.keys()), k=(1,300))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e58da9a",
   "metadata": {},
   "source": [
    "If you change the value of k with the slider, you will see that the quality of the image changes. The graph next to the image illustrates the distribuition of the singular values. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

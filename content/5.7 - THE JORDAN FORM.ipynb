{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "4fba9e9d-b5f8-47ff-a14d-23ac10c9208f",
      "cell_type": "markdown",
      "source": "# The Jordan Form\nWe can take into account the generalized eigenvectors of a matrix in order to extend the\neigenvalue-eigenvector equation in matrix form, as follows. Let $A$ be a generic linear operator in\n$\\mathcal{U}$, with $\\dim(\\mathcal{U})=n$. Let $V$ be a matrix whose columns are the generalized\neigenvectors of $A$\n\nIf $A$ cannot be diagonalized, then the Jordan form provides the most simplified structure achievable via\nsimilarity transformations. Any matrix $A \\in \\mathbb{C}^{n\\times n}$ can be transformed into a Jordan\ncanonical form $J$ through an invertible matrix $T$ such that:\n\n$$T^{-1} A T = J =\n\\begin{bmatrix}\nJ_1 &        &        \\\\\n    & \\ddots &        \\\\\n    &        & J_q\n\\end{bmatrix}$$\n\nEach $J_i$ is called a **Jordan block**, associated with eigenvalue\n$\\lambda_i$:\n\n$$J_i =\n\\begin{bmatrix}\n\\lambda_i & 1        &          &        \\\\\n          & \\lambda_i & \\ddots   &        \\\\\n          &          & \\ddots   & 1      \\\\\n          &          &          & \\lambda_i\n\\end{bmatrix}\n\\in \\mathbb{C}^{n_i \\times n_i}$$  \n  \nThe matrix $J$ is block-diagonal, with the total dimension $n = \\sum_{i=1}^{q} n_i$. The goal is to choose $T$\nsuch that $J$ is as close to diagonal as possible.\n\nIf $A$ has a complete set of $n$ linearly independent eigenvectors, they can be placed in the columns of $T$\n(so $T = X$), and $X^{-1} A X$ is diagonal. In this case, the Jordan form of $A$ is simply a diagonal matrix.\nThis corresponds to the situation where each Jordan block has size 1. Note that the Jordan form is **unique up\nto the order of the Jordan blocks**. That is, although the arrangement of the blocks may vary, the number,\nsize, and associated eigenvalues of the blocks are uniquely determined by the matrix $A$.\n\nIn the general case where $A$ does not have enough linearly independent eigenvectors, the Jordan form still\nprovides a canonical representation. Suppose $A$ has $s$ linearly independent eigenvectors. Then it is similar\nto a Jordan matrix $J$ with $s$ blocks. Each block corresponds to one eigenvector and contains the eigenvalue\nalong the diagonal and ones just above the diagonal.  The number of Jordan blocks corresponds to the geometric\nmultiplicity of the eigenvalue, while the size and number of repeated eigenvalues relate to the algebraic\nmultiplicity. When the geometric multiplicity is less than the algebraic multiplicity, the Jordan form will\ncontain multiple Jordan blocks for the same eigenvalue, possibly of different sizes.",
      "metadata": {}
    },
    {
      "id": "04e73d98-6324-4a5c-ae50-b2b1471d7011",
      "cell_type": "markdown",
      "source": "# Application: Markov Chains\nA Markov chain is a mathematical system that experiences transitions from one state to another according to certain probabilistic rules. A Markov chain is also a stochastic (random) process, but it differs from a general stochastic process in that a Markov chain must be \"memory-less.\" That is, (the probability of) future actions are not dependent upon the steps that led up to the present state. This is called the Markov property. While the theory of Markov chains is important precisely because so many \"everyday\" processes satisfy the Markov property, there are many common examples of stochastic properties that do not satisfy the Markov property. The state space, or set of all possible states, can be anything (letters, numbers, weather conditions, etc).\n\n![image.png](https://d18l82el6cdm1i.cloudfront.net/uploads/8izeywKSRU-stochastic-process-not-markov.gif)\n\n![image.png](https://d18l82el6cdm1i.cloudfront.net/uploads/I1p8Np0BlO-stochastic-process-is-markov.gif)",
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "b5ddfa6f-94de-439c-9eed-c3c77c617f86",
      "cell_type": "markdown",
      "source": "The evolution of the system is governed by a transition matrix $P$, where each element $p_ij$ represents:   \n$$\\mathbf{p_ij = P (next state = j| current state = i)}$$  \nand each row of $P$ sums to 1.  \n",
      "metadata": {}
    },
    {
      "id": "ed4147c5-2f5d-4cb8-af3f-556fa8d7cc8b",
      "cell_type": "markdown",
      "source": "The probability distribution of states at step $n$ is given by:  \n$$\\mathbf{\\pi_n = \\pi_0 P^n} $$  \nwhere:  \n- $\\mathbf{\\pi}$ is the initial probability vector,  \n- $\\mathbf{P^n}$ is the n-th power of $\\mathbf{P}$.",
      "metadata": {}
    },
    {
      "id": "6dafd80f-0f6f-44a5-aa6c-668e410bd955",
      "cell_type": "markdown",
      "source": "To find the probability distribution after $n$ steps ($\\mathbf{\\pi_n}$), we must compute $P^n$.   \n\n__Notice:__ We are usually interested in the __steady-state distribution__ ($\\mathbf{\\pi_\\infty}$)that happens when $n$ is large.  \n$$\\mathbf{\\pi_\\infty = lim_{n\\to\\infty} \\pi_0 P^n}$$",
      "metadata": {}
    },
    {
      "id": "dfbedf62-a2c2-4df9-b628-b0da32c2b697",
      "cell_type": "markdown",
      "source": "## If $P$ is Diagonalizable  \nA key property of any stochastic matrix $\\mathbf{P}$ is that it always has at least one eigenvalue equal to 1. The eigenvector associated with the eigenvalue 1 corresponds to the steady-state distribution. All other eigenvalues have absolute value less than 1, wich means their contributions decay to zero as $\\mathbf{n}$ tends to infinity.",
      "metadata": {}
    },
    {
      "id": "cea0e9b0-d1e5-4ec3-91a8-403f5b7a4ab9",
      "cell_type": "markdown",
      "source": "Suppose we can diagonalize $\\mathbf{P}$, so we compute $\\mathbf{P^n}$ by  \n$$\\mathbf{P = VDV^{-1}}$$  \nthen  \n$$\\mathbf{P^n = VD^{n}V^{-1}}$$  \nand $\\mathbf{D^n = diag(\\lambda_1^n, \\lambda_2^n, lambda_3^n,\\dots)}$.   \nas $\\mathbf{lim_{n\\to\\infty}}$, $\\mathbf{\\lambda_2^n, \\lambda_3^n, lambda_4^n,\\dots}$ all go to zero, leaving only the eigenvalue 1.",
      "metadata": {}
    },
    {
      "id": "113fd694-b80c-4317-8d70-5792f16cb12c",
      "cell_type": "markdown",
      "source": "## What if $P$ is not Diagonalizable ?\n",
      "metadata": {}
    },
    {
      "id": "efd703d6-3d3b-4bbb-bb73-f5644a205701",
      "cell_type": "markdown",
      "source": "Sometimes, a matrix cannot be diagonalized because it does not have enough independent eigenvectors. This is where Jordan form comes into play, once it simplifies the computation of $\\mathbf{P^n}$. In this case, we use the Jordan canonical form:  \n$$\\mathbf{P = VJV^{-1}} $$  \nwhere $J$ is composed by Jordan blocks. So we'll find:  \n$$\\mathbf{P^n = VJ^{n}V^{-1}} $$",
      "metadata": {}
    },
    {
      "id": "5d8928b9-24ca-428b-a543-e0fc7029f674",
      "cell_type": "markdown",
      "source": "The block with $\\lambda = 1$ dominates as $lim_{n\\to\\infty}$. Other blocks with $|\\lambda| < 1$ will decay to zero. ",
      "metadata": {}
    },
    {
      "id": "2df2cdb0-3c98-4878-8ee2-a3412860c9a9",
      "cell_type": "markdown",
      "source": "## The behavior of a Capacitor using the Markov Chain",
      "metadata": {}
    },
    {
      "id": "00da17d1-fb9a-47d1-8b1e-404f7c5daa23",
      "cell_type": "markdown",
      "source": "Imagine a capacitor that, at each time step:\n\n- **Charges** (goes to a higher state) with probability $p$.\n- **Discharges** (goes to a lower charge state) with probability $1-p$\n\nWe can discretize the capacitor's charge into **3 states**:  \n\n- **State 0**: Empty (0% charged)\n- **State 1**: Half Charged (50% charged)\n- **State 2**: Fully Charged (100% charged)\n\nThe transition matrix $\\mathbf{P}$ might look like:  \n\n$$ \\mathbf{P} = \n\\begin{bmatrix}\n0.7 & 0.2 & 0.1 \\\\\n0.1 & 0.8 & 0.1 \\\\\n0.0 & 0.3 & 0.7 \\\\\n\\end{bmatrix}\n$$  \nwhere the elements of each rows sum to 1.  \nIf the capacitor is empty (State 0) it can stay empty with 70% probability, get half charged (State 1) with 20% probability or get fully charged (State 2) with 10% probability. If it’s half-charged (State 1), it may discharge (10%), stay the same (80%), or charge further (10%). If it’s full (State 2), it may discharge to State 1 (30%) or remain full (70%). Notice that we are using $$\\mathbf{\\pi_n = \\pi_0 P^n} $$ so $\\mathbf{\\pi_0}$ (initial state) is initialized in the code (you can modify it). \n\nAfter inserting all the necessary information and pressing the \"Calculate\" button, you'll be able to see:  \n\n- **Transient behavior**: It shows how the probabilities of being in each charge state evolve over time, starting from an empty capacitor.\n- **Steady-state distribution**: The capacitor reaches a statistical equilibrium, where probabilities of being in each charge state remain constant.\n- **Mixing time prediction**: Using the second-largest eigenvalue of $\\mathbf{P}$, we estimate how quickly the system converges to its steady state.\n\n**Mixing time** is a concept that describes how fast a Markov chain converges to its steady-state distribution (equilibrium), regardless of the starting state.  \n$$\nt_{\\text{mix}} \\approx \\left\\lceil \\frac{\\log(\\epsilon)}{\\log(\\lambda_2)} \\right\\rceil\n$$\nAnother important concept is the **Total Variation Distance**, where we calculate the absolute distance between the current probability distribution $\\mathbf{\\pi_k}$ and the steady-state distribution $\\mathbf{\\pi_\\infty}$. If the distance is smaller than the defined tolerance ($\\epsilon$), so we can say we got the steady-state distribution.\n$$\n\\|\\pi_k - \\pi_\\infty\\|_1 = \\sum_i |\\pi_k(i) - \\pi_\\infty(i)|\n$$\nNow it's time to work!",
      "metadata": {}
    },
    {
      "id": "7afee836-566a-49dd-ba40-937a9b72d110",
      "cell_type": "code",
      "source": "%pip install -q ipywidgets==8.0.7\n%pip install sympy",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "id": "7e7655d6-c259-49ec-b62a-40e7cc599cdb",
      "cell_type": "code",
      "source": "# Interactive Markov notebook with Jordan fallback and robust distance plotting\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom numpy.linalg import eig, matrix_rank, inv\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output\n\n# Widgets for a 3x3 matrix\nmatrix_inputs = [[widgets.BoundedFloatText(value=0.0, min=0, max=1, step=0.01, layout=widgets.Layout(width='80px')) for _ in range(3)] for _ in range(3)]\n\n# Example default matrix (non-diagonalizable example)\ndefault = [\n    [1.0, 0.0, 0.0],\n    [0.5, 0.5, 0.0],\n    [0.0, 0.5, 0.5]\n]\nfor i in range(3):\n    for j in range(3):\n        matrix_inputs[i][j].value = default[i][j]\n\nmatrix_box = widgets.VBox([widgets.HBox(row) for row in matrix_inputs])\ncalculate_button = widgets.Button(description=\"Calculate\", button_style='success')\noutput_area = widgets.Output()\n\n# Helper to attempt sympy import once\n_sympy_available = None\ndef _check_sympy():\n    global _sympy_available\n    if _sympy_available is not None:\n        return _sympy_available\n    try:\n        import sympy as sp  # noqa: F401\n        _sympy_available = True\n    except Exception:\n        _sympy_available = False\n    return _sympy_available\n\ndef compute_power_via_sympy(P, n):\n    \"\"\"Use sympy to compute P**n and return a numpy float array (if sympy installed).\"\"\"\n    import sympy as sp\n    P_sym = sp.Matrix(P)\n    Pn_sym = P_sym**n  # sympy computes integer powers symbolically (works for Jordan cases)\n    Pn_np = np.array(Pn_sym.evalf(), dtype=np.float64)\n    return Pn_np\n\ndef compute_markov(_):\n    with output_area:\n        clear_output(wait=True)\n        \n        # Read P from widgets\n        P = np.array([[cell.value for cell in row] for row in matrix_inputs], dtype=float)\n        print(\"Transition Matrix P:\")\n        print(P)\n        \n        # Row-stochastic check\n        row_sums = P.sum(axis=1)\n        if not np.allclose(row_sums, 1, atol=1e-8):\n            print(\"\\n⚠️ Warning: Each row of P should sum to 1 (row sums shown below).\")\n            print(\"Row sums:\", row_sums)\n        \n        n_steps = 50  # simulation steps for transient\n        pi0 = np.array([1.0, 0.0, 0.0])  # initial distribution (you can change)\n        \n        # --- eigen decomposition for diagnostics ---\n        eigvals, eigvecs = eig(P)\n        print(\"\\nEigenvalues of P:\")\n        print(np.round(eigvals, 8))\n        \n        print(\"\\nEigenvectors of P (columns):\")\n        np.set_printoptions(suppress=True, precision=6)\n        print(eigvecs)\n        \n        # Check diagonalizability: eigenvector matrix must be full rank\n        rank_V = matrix_rank(eigvecs)\n        print(f\"\\nRank of eigenvector matrix: {rank_V} (needs {P.shape[0]} to be diagonalizable)\")\n        \n        # Prepare pi_list using appropriate method (diagonalization or Jordan/sympy/fallback)\n        pi_list = [pi0.copy()]\n        \n        if rank_V == P.shape[0]:\n            # Diagonalizable: use eigendecomposition\n            print(\"\\nMatrix is diagonalizable. Computing powers using eigendecomposition...\")\n            V = eigvecs\n            V_inv = inv(V)\n            for k in range(1, n_steps):\n                Dk = np.diag(eigvals**k)\n                Pk = V @ Dk @ V_inv\n                pi_list.append((pi0 @ Pk).real)\n        else:\n            # Not diagonalizable -> try sympy (Jordan-like) or fallback\n            print(\"\\nThe matrix P is NOT diagonalizable. We will compute P^k using a Jordan-capable method (SymPy).\")\n            if _check_sympy():\n                try:\n                    import sympy as sp\n                    print(\"SymPy available: using symbolic matrix power (handles Jordan cases).\")\n                    for k in range(1, n_steps):\n                        Pk = compute_power_via_sympy(P, k)\n                        pi_list.append(pi0 @ Pk)\n                except Exception as e:\n                    print(\"SymPy attempt failed with error:\", e)\n                    print(\"Falling back to repeated multiplication (safe but slower).\")\n                    Pk = np.eye(P.shape[0])\n                    for k in range(1, n_steps):\n                        Pk = Pk @ P\n                        pi_list.append(pi0 @ Pk)\n            else:\n                print(\"SymPy not installed. Falling back to repeated multiplication (safe but slower).\")\n                Pk = np.eye(P.shape[0])\n                for k in range(1, n_steps):\n                    Pk = Pk @ P\n                    pi_list.append(pi0 @ Pk)\n        \n        pi_array = np.array(pi_list)\n        # Clip tiny negatives from numerical noise\n        pi_array = np.clip(pi_array, 0.0, 1.0)\n        \n        # Compute steady-state (from P^T eigenvector of lambda=1)\n        eigvals_T, eigvecs_T = eig(P.T)\n        mask_one = np.isclose(eigvals_T, 1.0)\n        if np.any(mask_one):\n            v = eigvecs_T[:, mask_one][:, 0].real\n            # Fix sign and normalize\n            if np.all(v <= 0):\n                v = -v\n            # If components are tiny negative due to numeric, clip\n            v = np.clip(v, 0.0, None)\n            if v.sum() == 0:\n                # fallback if zero vector numerically\n                steady = pi_array[-1]\n                print(\"\\nNumerical issue: eigenvector for lambda=1 is zero after clipping; using last simulated distribution as steady-state.\")\n            else:\n                steady = v / v.sum()\n        else:\n            steady = pi_array[-1]\n            print(\"\\nNote: exact eigenvalue 1 not found numerically; using last simulated distribution as steady-state.\")\n        \n        print(\"\\nSteady-State Distribution (normalized):\")\n        print(np.round(steady, 8))\n        \n        # Plot transient behavior\n        plt.figure(figsize=(8, 5))\n        for i in range(P.shape[0]):\n            plt.plot(range(n_steps), pi_array[:, i], label=f\"State {i}\")\n            plt.axhline(steady[i], color='gray', linestyle='--')\n        plt.title(\"Transient Behavior of Markov Chain\")\n        plt.xlabel(\"Steps\")\n        plt.ylabel(\"Probability\")\n        plt.legend()\n        plt.grid(True)\n        plt.tight_layout()\n        plt.show()\n        \n        # Distance to steady-state and mixing time\n        tolerance = 1e-3\n        distances = [np.linalg.norm(pi - steady, ord=1) for pi in pi_array]\n        distances = np.maximum(distances, 0.0)  # ensure non-negative\n        \n        # find first step below tolerance (including step 0)\n        close_step_including0 = next((k for k, d in enumerate(distances) if d < tolerance), n_steps)\n        # If you prefer to ignore step 0 and find first positive step, uncomment below:\n        # close_step_excluding0 = next((k for k, d in enumerate(distances[1:], start=1) if d < tolerance), n_steps)\n        \n        print(f\"\\nThe chain gets within {tolerance} of the steady-state distribution at step: {close_step_including0}\")\n        # If you used the excluding0, print that instead:\n        # print(f\"The chain (excluding initial) first gets within ... at step: {close_step_excluding0}\")\n        \n        # Show distance plot: semilogy only if all distances > 0\n        plt.figure(figsize=(6,3))\n        if np.all(np.array(distances) > 0):\n            plt.semilogy(range(n_steps), distances, marker='o')\n        else:\n            # Use linear plot when zeros are present to avoid log(0)\n            plt.plot(range(n_steps), distances, marker='o')\n        plt.axhline(tolerance, color='red', linestyle='--', label=f'tolerance = {tolerance}')\n        if close_step_including0 < n_steps:\n            plt.axvline(close_step_including0, color='green', linestyle='--', label=f'close at step {close_step_including0}')\n        plt.title('Distance to steady-state (L1 norm)')\n        plt.xlabel('Steps')\n        plt.ylabel('L1 distance')\n        plt.legend()\n        plt.grid(True, which='both', ls=':')\n        plt.tight_layout()\n        plt.show()\n        \n        # Mixing time estimate from second largest eigenvalue (abs)\n        eigvals_abs = np.sort(np.abs(eigvals))[::-1]\n        if eigvals_abs.size > 1 and eigvals_abs[1] < 1 and eigvals_abs[1] > 0:\n            lambda2 = eigvals_abs[1]\n            import math\n            mixing_est = int(np.ceil(math.log(tolerance) / math.log(lambda2)))\n            print(f\"Estimated mixing time (based on eigenvalue {lambda2:.6f}): {mixing_est} steps\")\n        else:\n            print(\"Unable to estimate mixing time from eigenvalues (second eigenvalue >= 1, zero, or missing).\")\n\n# Hook up button\ncalculate_button.on_click(compute_markov)\n\n# Display UI\ndisplay(widgets.HTML(\"<h3>Enter Transition Matrix P (rows must sum to 1):</h3>\"))\ndisplay(matrix_box)\ndisplay(calculate_button)\ndisplay(output_area)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HTML(value='<h3>Enter Transition Matrix P (rows must sum to 1):</h3>')",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e801fdef07294d31918a08ecd5ea13a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(HBox(children=(BoundedFloatText(value=1.0, layout=Layout(width='80px'), max=1.0, step=0.01), Bo…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f30a6ba614e4bad99f6788fcc7e3d5f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Button(button_style='success', description='Calculate', style=ButtonStyle())",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ff197140f1747c7b98c0e90285680ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Output()",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6003aed595ae4a0b81af363ae2b47fdd"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 6
    },
    {
      "id": "11e230b4-9468-4274-a417-8f80ffa57e7b",
      "cell_type": "markdown",
      "source": "### Important Questions \n\n- What can you infer about the plotted patterns when P is diagonalizable?\n- If you normalize the eigenvector associated with the eigenvalue 1, what will you get?\n- What can you infer about the plotted patterns when P is NOT diagonalizable?\n- Why is one eigenvalue always 1 in a valid transition matrix?\n- What do the other eigenvalues tell us about the speed of convergence to the steady state?\n- What does it mean if the eigenvectors matrix is not full rank?\n- How does the method for computing $\\mathbf{P^n}$change if is not diagonalizable?\n- Why is Jordan form important in such cases?\n- What does the **L1** distance $\\|\\pi_k - \\pi_\\infty\\|_1$  represent?\n- What does it mean if the distance drops to zero at step 0?\n- How is the mixing time estimated from the second-largest eigenvalue?\n- Why does a larger $\\mathbf{|\\lambda_2|}$ imply slower convergence?\n\n## Bibliography\nhttps://brilliant.org/wiki/markov-chains/  \nhttps://brilliant.org/wiki/transience-and-recurrence/  \nhttp://www.tcs.hut.fi/Studies/T-79.250/tekstit/lecnotes_02.pdf  \nhttps://ocw.mit.edu/courses/6-071j-introduction-to-electronics-signals-and-measurement-spring-2006/4b6a5fe626d65de20ceb97d8d23f38a4_transient1_rl_rc.pdf",
      "metadata": {}
    },
    {
      "id": "37e45ed2-876f-46be-b872-3a26174932e9",
      "cell_type": "markdown",
      "source": "<br>\n<p style=\"text-align:left;\">\n    <a href=\"5.6 - GENERALIZED EIGENVECTORS.ipynb\">⬅️PREVIOUS</a>\n</p>",
      "metadata": {}
    }
  ]
}